<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students 2025" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group DeepText Analysts, Reflective Report, " />

<meta property="og:title" content="Decoding Crypto Volatility: Leveraging NLP to Predict TerraLuna&#39;s Market Performance (by Group &#34;DeepText Analysts&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/DeepText Analysts.html" />
<meta property="og:description" content="By Group &#34;DeepText Analysts&#34; The Digital Gold Rush: Why Cryptocurrency Analysis Matters Now Our team, DeepText Analysts, is investigating whether natural language processing (NLP) can predict cryptocurrency performance, with a specific focus on TerraLuna. This research carries significant implications due to the cryptocurrency industry&#39;s explosive growth, increasing mainstream adoption by …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2025" />
<meta property="og:article:author" content="FINA4350 Students 2025" />
<meta property="og:article:published_time" content="2025-03-24T23:59:00+08:00" />
<meta name="twitter:title" content="Decoding Crypto Volatility: Leveraging NLP to Predict TerraLuna&#39;s Market Performance (by Group &#34;DeepText Analysts&#34;) ">
<meta name="twitter:description" content="By Group &#34;DeepText Analysts&#34; The Digital Gold Rush: Why Cryptocurrency Analysis Matters Now Our team, DeepText Analysts, is investigating whether natural language processing (NLP) can predict cryptocurrency performance, with a specific focus on TerraLuna. This research carries significant implications due to the cryptocurrency industry&#39;s explosive growth, increasing mainstream adoption by …">

        <title>Decoding Crypto Volatility: Leveraging NLP to Predict TerraLuna&#39;s Market Performance (by Group &#34;DeepText Analysts&#34;)  · FINA4350 Student Blog 2025
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2025 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/"><span class=site-name>FINA4350 Student Blog 2025</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2025-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/DeepText Analysts.html">
                Decoding Crypto Volatility: Leveraging NLP to Predict TerraLuna's Market Performance (by Group "DeepText Analysts")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>By Group "DeepText Analysts"</p>
<h1>The Digital Gold Rush: Why Cryptocurrency Analysis Matters Now</h1>
<p>Our team, DeepText Analysts, is investigating whether natural language processing (NLP) can predict cryptocurrency performance, with a specific focus on TerraLuna. This research carries significant implications due to the cryptocurrency industry's explosive growth, increasing mainstream adoption by businesses, persistent market volatility, and the need for better investment decision support tools.</p>
<p>The intersection of NLP and cryptocurrency markets represents a promising frontier in fintech research, with practical applications for risk management and investment strategy development in this rapidly evolving but highly unpredictable financial landscape.</p>
<p>By applying sentiment analysis to social media discussions and other information sources, we aim to develop models that might forecast crypto market movements. The dramatic collapse of TerraLuna serves as our central case study, raising the question: Could sentiment analysis have provided early warning signals before the crash?</p>
<h4>About TerraLuna</h4>
<p>TerraLuna is a decentralised blockchain platform containing TerraUSD, an algorithmic stablecoin that was backed by LUNA, a native token which provides an arbitrage opportunity by absorbing the short-term volatilities of TerraUSD. TerraUSD’s unique concept of securing stability with LUNA instead of normal asset reserves appeared successful as the 8th largest market capitalisation in cryptocurrency in April 2022. Luna’s sudden crash on May 9th, 2022 was caused by over $2 billion worth of UST being unstaked which depegged the stablecoin and caused crypto exchanges to delist LUNA and UST pairings. This made LUNA worthless, resulting in significant consequences to the highly volatile cryptocurrency market and Luna investors.  </p>
<p>Due to TerraLuna’s strong past performance, the company’s loyal fans, known as Lunatics used to frequently share their thoughts and discussions on Reddit. Thus, given the copious amount of available data and the complete price history on the growth and downfall of TerraLuna, we plan to use this information to train our model which we hope can analyse and predict cryptocurrency performance based on public sentiment on other cryptocurrencies.</p>
<h1>Our Methodology</h1>
<p>To start our data workflow, we have carefully considered the various types of data sources to establish as our foundational framework. We have structured our thought process around several key factors: the nature of the data source, the category of cryptocurrency, and the timeline of our data, and the methodology we employ to measure sentiment analysis. Each of these elements plays a critical role in ensuring the robustness and accuracy of our research. </p>
<p>Firstly, with our data source, we decided to start working on Reddit posts, an online social media platform which offers a rich database on a diverse range of topics. We chose to focus on the comment section which makes it particularly easy to find insightful discussions and news articles related to cryptocurrency, especially on the subject of TerraLuna. Next, we established a specific timeline for our data collection, focusing on posts from the year 2020, when cryptocurrency was gaining popularity, to 2022, just prior to the collapse of TerraLuna. With this timeframe, we can properly evaluate whether our results align with the actual historical outcomes of the cryptocurrency market, ensuring the relevance and accuracy of our analysis. </p>
<p>Taking all these factors into account, this serves as our foundational base case. Our product is designed to offer flexibility, enabling the application of this methodology to any cryptocurrency by leveraging diverse data sources and analytical approaches, such as dictionary-based methods, deep learning techniques, or Python packages. Once our system is established using this base case, we will expand our exploration to incorporate a variety of scenarios and methodologies.</p>
<h1>Breaking the Code: Our Multi-Faceted Approach to Crypto Prediction</h1>
<h4>Model 1: Dictionary-Based Sentiment Analysis</h4>
<p>We're analyzing thousands of Reddit threads related to TerraLuna using lexicon-based sentiment analysis techniques. This approach leverages the Loughran-McDonald Dictionary, which was specifically developed for financial text analysis and captures finance-specific terminology that general sentiment dictionaries often misclassify. The dictionary categorizes words into six sentiment categories (positive, negative, uncertainty, litigious, strong modal, and constraining), allowing us to detect nuanced financial sentiment beyond simple polarity. Each comment is processed to extract these specialized sentiment metrics, enabling us to track shifts in investor confidence, uncertainty, and regulatory concerns within the TerraLuna community over time. We're particularly focused on identifying sentiment patterns that preceded major price volatility during the collapse.</p>
<h4>Model 2: Advanced Deep Learning Architecture</h4>
<p>We're developing sophisticated neural network models—including BERT (Bidirectional Encoder Representations from Transformers) and FinBERT (Financial domain-specific BERT)—that can capture nuanced relationships between language patterns and market movements. These transformer-based models excel at understanding context and can be fine-tuned on cryptocurrency-specific language. Unlike dictionary methods, these approaches can recognize complex linguistic patterns, sarcasm, and emerging terminology common in crypto communities.</p>
<h1>Potential Additional Methods to Explore</h1>
<h4>Topic Modeling with LDA (Latent Dirichlet Allocation)</h4>
<p>By implementing topic modeling, we could identify emerging discussion themes that correlate with market shifts. This would help us understand not just sentiment polarity but the specific concerns driving community reactions.</p>
<h4>Time Series Forecasting with LSTM Networks</h4>
<p>Long Short-Term Memory networks could help us better model the temporal dynamics between sentiment shifts and price movements, accounting for both immediate and delayed effects.</p>
<h4>Hybrid NLP-Technical Analysis</h4>
<p>Combining our NLP insights with traditional technical indicators (RSI, MACD, Bollinger Bands) could yield a more comprehensive prediction model that considers both market psychology and price action patterns.</p>
<h4>Transfer Learning from Related Assets</h4>
<p>We could explore transfer learning techniques to leverage patterns discovered in other cryptocurrencies to enhance our TerraLuna predictions, potentially identifying universal sentiment indicators across the crypto market.</p>
<h4>Named Entity Recognition for Key Influencers</h4>
<p>Implementing named entity recognition could help us identify and track key influencers whose opinions disproportionately impact market sentiment and price movements.</p>
<h1>Current Progress</h1>
<p>Our data collection phase has been fascinating. We've gathered Reddit discussions about TerraLuna. This code shows how we used the Reddit API for data collection:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">praw</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">openpyxl</span>
<span class="kn">import</span> <span class="nn">datetime</span>

<span class="c1"># initialize Reddit API</span>
<span class="n">reddit</span> <span class="o">=</span> <span class="n">praw</span><span class="o">.</span><span class="n">Reddit</span><span class="p">(</span>
    <span class="n">client_id</span><span class="o">=</span><span class="s1">&#39;ZExuVDrnuon1q8SWA__2fw&#39;</span><span class="p">,</span>
    <span class="n">client_secret</span><span class="o">=</span><span class="s1">&#39;TENjvYzdpCZV2tA8gwA_8bEkyNfghg&#39;</span><span class="p">,</span>
    <span class="n">user_agent</span><span class="o">=</span><span class="s1">&#39;ImportanceAsleep6865&#39;</span><span class="p">,</span>
<span class="p">)</span>


<span class="n">subreddit</span> <span class="o">=</span> <span class="n">reddit</span><span class="o">.</span><span class="n">subreddit</span><span class="p">(</span><span class="s2">&quot;cryptocurrency&quot;</span><span class="p">)</span>
<span class="n">query</span> <span class="o">=</span> <span class="s2">&quot;Terra OR Luna&quot;</span>
<span class="n">search_results</span> <span class="o">=</span> <span class="n">subreddit</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">limit</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>

<span class="c1"># time range(2021.1 - 2022.6)</span>
<span class="n">start_timestamp</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>  <span class="c1"># 2019-01-01</span>
<span class="n">end_timestamp</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="p">(</span><span class="mi">2022</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">())</span>  <span class="c1"># 2022-06-30</span>

<span class="c1"># filter and save to DataFrame</span>
<span class="n">filtered_posts</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Title&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;Post URL&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;Created At&quot;</span><span class="p">:</span> <span class="p">[]}</span>

<span class="k">for</span> <span class="n">post</span> <span class="ow">in</span> <span class="n">search_results</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">start_timestamp</span> <span class="o">&lt;=</span> <span class="n">post</span><span class="o">.</span><span class="n">created_utc</span> <span class="o">&lt;=</span> <span class="n">end_timestamp</span><span class="p">:</span>
        <span class="n">filtered_posts</span><span class="p">[</span><span class="s2">&quot;Title&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">title</span><span class="p">)</span>
        <span class="n">filtered_posts</span><span class="p">[</span><span class="s2">&quot;Post URL&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">permalink</span><span class="p">)</span>
        <span class="n">filtered_posts</span><span class="p">[</span><span class="s2">&quot;Created At&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">datetime</span><span class="o">.</span><span class="n">fromtimestamp</span><span class="p">(</span><span class="n">post</span><span class="o">.</span><span class="n">created_utc</span><span class="p">))</span>

<span class="c1"># convert to Pandas DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">filtered_posts</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;terra_luna_posts.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot; There are </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)</span><span class="si">}</span><span class="s2"> of post satisified the requirement and saved to terra_luna_posts.csv&quot;</span><span class="p">)</span>
</code></pre></div>

<p>Then we created visualizations including word clouds that reveal common themes and concerns among community members. This is important for us as we might have to filter based on themes/words which comments in the dataset are actually relevant. </p>
<p><img alt="Picture showing Word Cloud" src="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/images/DeepText-Analysts-01-word-cloud.jpg"></p>
<p>Words like "lost," "deleted," "shit," "ponzi," and "scam" indicate negativity, possibly referring to financial losses or scams."Good," "great," and "better" suggest some positive views, but they are relatively smaller.
Frequent mentions of "money," "price," "value," and "market" indicate concerns about investment performance.Words like "buy," "sell," "risk," "stable," and "USD" imply discussions about trading, stability, and financial decisions.
We've also compiled historical price-volume data to correlate with our sentiment metrics.</p>
<p><img alt="Picture showing Price Volume" src="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/images/DeepText-Analysts-01-price-volume-chart.png"></p>
<p>Based on this figure, we can see the price surge and fall of Terra Luna. The price experienced a significant rise from early 2021, peaking around late 2021 or early 2022. After reaching its peak, the price exhibited some volatility but remained high until mid-2022. A sharp and dramatic collapse occurred around mid-2022, where the price dropped to near zero and remained flat afterward.
Trading volume fluctuated throughout the period, with occasional spikes corresponding to price movements.There was a massive spike in trading volume around the time of the price crash, indicating panic selling or forced liquidations.After the collapse, trading volume also significantly decreased, suggesting reduced interest or market activity.  </p>
<p>Initial tests using our dictionary method have yielded intriguing but statistically insignificant results:  </p>
<p>We started off simple by just calculating a negativity score for each comment, based on the classification of the Loughran-McDonald Dictionary. We then aggregated and averaged those scores for each day and compared it to the price movement.  </p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">kagglehub</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">from</span> <span class="nn">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;punkt_tab&#39;</span><span class="p">)</span>  <span class="c1"># For tokenization</span>
<span class="kn">import</span> <span class="nn">ast</span>  <span class="c1"># For safely parsing string lists</span>

<span class="c1"># Step 1: Load Loughran-McDonald Dictionary</span>
<span class="n">lm_dict</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;Loughran-McDonald_Dictionary.csv&#39;</span><span class="p">)</span>

<span class="c1"># Extract negative words (where &#39;Negative&#39; column &gt; 0)</span>
<span class="n">negative_words</span> <span class="o">=</span> <span class="n">lm_dict</span><span class="p">[</span><span class="n">lm_dict</span><span class="p">[</span><span class="s1">&#39;Negative&#39;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">][</span><span class="s1">&#39;Word&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Loaded </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_words</span><span class="p">)</span><span class="si">}</span><span class="s2"> negative words from LM Dictionary&quot;</span><span class="p">)</span>

<span class="c1"># Step 2: Load the test dataset from BTC.csv</span>
<span class="c1"># Replace &#39;BTC.csv&#39; with your actual file path if different</span>
<span class="n">headlines_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;BTC.csv&#39;</span><span class="p">)</span>

<span class="c1"># Step 3: Define sentiment scoring function</span>
<span class="k">def</span> <span class="nf">get_lm_negativity_score</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="c1"># Tokenize the headline into words</span>
    <span class="n">words</span> <span class="o">=</span> <span class="n">word_tokenize</span><span class="p">(</span><span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">total_words</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>

    <span class="c1"># Count negative words</span>
    <span class="n">neg_count</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">words</span> <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">negative_words</span><span class="p">)</span>

    <span class="c1"># Calculate negativity score (proportion of negative words)</span>
    <span class="k">if</span> <span class="n">total_words</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    <span class="k">return</span> <span class="n">neg_count</span> <span class="o">/</span> <span class="n">total_words</span>  <span class="c1"># Range: 0 to 1 (higher = more negative)</span>

<span class="sd">&#39;&#39;&#39;[# Step 4: Function that applies &quot;get_lm_negativity_score&quot; on each comment]&#39;&#39;&#39;</span>

<span class="c1"># Step 5: Calculate daily average negativity score</span>
<span class="c1"># Convert Comment Time to datetime and extract date only</span>
<span class="n">comments_df</span><span class="p">[</span><span class="s1">&#39;Comment Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">comments_df</span><span class="p">[</span><span class="s1">&#39;Comment Time&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span>
<span class="n">daily_negativity</span> <span class="o">=</span> <span class="n">comments_df</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;Comment Date&#39;</span><span class="p">)[</span><span class="s1">&#39;negativity_score&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">daily_negativity</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;negativity_score&#39;</span><span class="p">:</span> <span class="s1">&#39;avg_negativity_score&#39;</span><span class="p">},</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Step 6: Load price data</span>
<span class="c1"># Replace &#39;terra-historical-day-data-all-tokeninsight.csv&#39; with your actual file path</span>
<span class="n">price_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;terra-historical-day-data-all-tokeninsight.csv&#39;</span><span class="p">)</span>

<span class="c1"># Step 7: Merge daily negativity scores with price data</span>
<span class="c1"># Ensure date formats match (convert price Date to date)</span>
<span class="n">price_df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">price_df</span><span class="p">[</span><span class="s1">&#39;Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span>
<span class="n">merged_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="n">daily_negativity</span><span class="p">,</span> <span class="n">price_df</span><span class="p">,</span> <span class="n">left_on</span><span class="o">=</span><span class="s1">&#39;Comment Date&#39;</span><span class="p">,</span> <span class="n">right_on</span><span class="o">=</span><span class="s1">&#39;Date&#39;</span><span class="p">,</span> <span class="n">how</span><span class="o">=</span><span class="s1">&#39;left&#39;</span><span class="p">)</span>

<span class="sd">&#39;&#39;&#39;[...]&#39;&#39;&#39;</span>
</code></pre></div>

<p>→ Our first trial analyzing all Reddit comments produced an R-squared value of only <strong>0.003</strong></p>
<p>These preliminary result suggested that our approach requires refinement. We did two smaller adjustments:  </p>
<p>a) Cutting off post-crash data in the regression analysis, as it might be insignificant noise at a time when the price is not really moving anymore:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="nn">sm</span>

<span class="c1"># Step 1: Load the Excel file with merged data</span>
<span class="c1"># Replace &#39;daily_negativity_and_prices.xlsx&#39; with your actual file path if different</span>
<span class="n">input_file</span> <span class="o">=</span> <span class="s1">&#39;daily_negativity_and_prices.xlsx&#39;</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="n">input_file</span><span class="p">)</span>

<span class="c1"># Step 2: Set timeframe (replace with desired start and end dates)</span>
<span class="n">start_date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2022-01-01&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">date</span><span class="p">()</span>  <span class="c1"># Example start date</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="s1">&#39;2022-05-15&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">date</span><span class="p">()</span>    <span class="c1"># Example end date | important: cutoff after crash</span>

<span class="c1"># Filter data based on timeframe</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Comment Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span> <span class="o">&gt;=</span> <span class="n">start_date</span><span class="p">)</span> <span class="o">&amp;</span>
        <span class="p">(</span><span class="n">pd</span><span class="o">.</span><span class="n">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Comment Date&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">dt</span><span class="o">.</span><span class="n">date</span> <span class="o">&lt;=</span> <span class="n">end_date</span><span class="p">)]</span>

<span class="c1"># Step 3: Prepare the data for regression</span>
<span class="c1"># Independent variable(s): avg_negativity_score</span>
<span class="c1"># Dependent variable: Price</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;avg_negativity_score&#39;</span><span class="p">]]</span>  <span class="c1"># Independent variable</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">add_constant</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># Add a constant term for the intercept</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Price&#39;</span><span class="p">]</span>  <span class="c1"># Dependent variable</span>

<span class="c1"># Step 4: Run multiple regression</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="o">.</span><span class="n">OLS</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>

<span class="c1"># Step 5: Display regression results</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Multiple Regression Results:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</code></pre></div>

<p>b) Filtering the comments to make it more likely that they are actually about TerraLuna and not only Bitcoin or completely different topics:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Step 1: Load the Excel file with Reddit comments</span>
<span class="c1"># Replace &#39;reddit_comments.xlsx&#39; with your actual file path</span>
<span class="n">comments_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s1">&#39;reddit_selected_rows.xlsx&#39;</span><span class="p">)</span>

<span class="c1"># Step 2: Transform data to filter comments containing &quot;terra&quot; or &quot;luna&quot; (case-insensitive)</span>
<span class="k">def</span> <span class="nf">filter_terra_luna_comments</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;Comment Text&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;terra|luna&#39;</span><span class="p">,</span> <span class="n">case</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">na</span><span class="o">=</span><span class="kc">False</span><span class="p">)]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

<span class="n">filtered_comments_df</span> <span class="o">=</span> <span class="n">filter_terra_luna_comments</span><span class="p">(</span><span class="n">comments_df</span><span class="p">)</span>

<span class="c1"># Step 3: Save to a new Excel file</span>
<span class="n">filtered_comments_df</span><span class="o">.</span><span class="n">to_excel</span><span class="p">(</span><span class="s1">&#39;filtered_reddit_selected_rows.xlsx&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Results saved to &#39;filtered_reddit_selected_rows.xlsx&#39;&quot;</span><span class="p">)</span>
</code></pre></div>

<p>→ Still, our second trial with selected comments similarly showed an R-squared of <strong>0.003</strong>  </p>
<p>Hence, we currently have further adjustments in mind:</p>
<ol>
<li>Trying to use a <strong>multiple discriminant analysis</strong>: calculating scores for every category of the Loughran-McDonald Dictionary and finding out which (combination of) categories is/are the most accurate predictor of price</li>
<li>Weighting comments based on community engagement (upvotes/downvotes)</li>
<li>Incorporating time lag analysis through cross-correlation to identify delayed effects  </li>
</ol>
<p>After getting the most out of the simple dictionary method, we will try to move on to a deep learning architecture. </p>
<h1>Technical Challenges and Lessons Learned</h1>
<p>One significant challenge we've encountered is distinguishing meaningful signals from noise in social media data. Cryptocurrency communities can be particularly reactive and emotional, making sentiment analysis complex.  </p>
<p>We've learned that simple correlation between sentiment scores and price movements doesn't capture the full relationship. Market dynamics likely involve multiple time scales and feedback loops that require more sophisticated modeling approaches.</p>
<h1>Next Steps</h1>
<p>Our team has established a detailed timeline for completing remaining tasks:  </p>
<ol>
<li>Refine our data collection processes</li>
<li>Improve our dictionary-based sentiment analysis model</li>
<li>Develop and train our deep learning model</li>
<li>Compare performance of both approaches</li>
<li>Document findings and prepare presentation  </li>
</ol>
<p>We're particularly excited about implementing cross-correlation analysis to better understand temporal relationships between sentiment shifts and price movements.</p>
<h1>Reflections on the Process</h1>
<p>We learned a lot in the first weeks of working on the project. The most striking lessons are: </p>
<ol>
<li>
<p>It is not easy at all to simply try to predict a price based on the sentiment. The initial major question that comes up is: is sentiment an accurate predictor of price? And if it is, it might still be very hard to get an accurate picture of the sentiment, that is, choosing the “right” sentiment data. Maybe people on Reddit are not moving the price, as they represent only small amounts of money. Is their thought actually relevant? If not, can we actually get the sentiment of those people who are moving the price? Either way, sentiment might still be lagging the price instead of predicting it. This is important to consider for further analysis. We are not only trying to make work something that does work for sure, but we also have to find out if it can work in the first place.  </p>
</li>
<li>
<p>While the knowledge we learn in this course and the existing Python libraries are of much help in the code work, the real work is still done by getting more familiar with statistical thinking. The issue so far was not to put an idea of a method to work, but rather to find the right method for our case. It was easy for us to calculate negativity scores and get sentiment data, but it turned out to be difficult to make the most of that data, as there are endless methods we could apply to it. Therefore, we saw the need to actually understand what is going on under the hood of the Python libraries we are using. We ran a polynomial-regression method to determine the correlation of the negativity scores and price, but it could well be that only extreme negativity scores are correlating with sharp price movements, and that everything else is simple noise. This would require a completely different model than a polynomial regression to predict price movements.  </p>
</li>
<li>
<p>Spending time together and doing regular meetings is absolutely essential and has helped us a lot. Since the beginning of the Semester, we met up almost every week and already developed a lot of great ideas together we probably would have not come up with alone. We also managed to distribute work effectively and are therefore confident that together we will be able to develop a model with more significant predictive power in the coming weeks. </p>
</li>
</ol>
<h1>Conclusion</h1>
<p>Our project represents an ambitious attempt to bridge the gap between qualitative online discourse and quantitative market outcomes. Though we haven't yet discovered a reliable predictive relationship, our exploration has yielded valuable insights into both the technical challenges of sentiment analysis and the complex dynamics of cryptocurrency markets.</p>
<p>We welcome feedback and suggestions as we continue to refine our approach and explore this fascinating intersection of technology and finance.</p>
<h1>References</h1>
<p>Forbes. (2022, September 20). What Really Happened To LUNA Crypto? Forbes. <a href="https://www.forbes.com/sites/qai/2022/09/20/what-really-happened-to-luna-crypto/">https://www.forbes.com/sites/qai/2022/09/20/what-really-happened-to-luna-crypto/</a>  </p>
<p>Lee, S., Lee, J., &amp; Lee, Y. (2022). Dissecting the Terra-LUNA crash: Evidence from the spillover effect and information flow. Finance Research Letters, 53(1544-6123). <a href="https://doi.org/10.1016/j.frl.2022.103590">https://doi.org/10.1016/j.frl.2022.103590</a></p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2025-03-24T23:59:00+08:00">Mon 24 March 2025</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/categories.html#reflective-report-ref">Reflective Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/tags.html#group-deeptext-analysts-ref">Group DeepText Analysts
                    <span class="superscript">1</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2025-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2025-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>